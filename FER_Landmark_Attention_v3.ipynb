{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67f5f6d",
   "metadata": {},
   "source": [
    "# Started from here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6426cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/lib/python3/dist-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "import heapq\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71d1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'data/merged/test/'\n",
    "train_dir = 'data/merged/train/'\n",
    "\n",
    "b_train_dir = 'data/balanced/'\n",
    "\n",
    "classes = os.listdir(train_dir)\n",
    "test_cls = os.listdir(train_dir)\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7dc0934-8a23-4c76-a883-9b27a75b2815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 7 \n",
      "Classes: ['fear', 'angry', 'sad', 'neutral', 'surprise', 'disgust', 'happy']\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'Number of classes: {num_classes}',\n",
    "    f'\\nClasses: {classes}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983c4b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Train--------\n",
      "fear: 8958\n",
      "angry: 8706\n",
      "sad: 10463\n",
      "neutral: 10721\n",
      "surprise: 7205\n",
      "disgust: 2910\n",
      "happy: 13445\n",
      "\n",
      "--------Test--------\n",
      "fear: 3374\n",
      "angry: 3272\n",
      "sad: 3916\n",
      "neutral: 4022\n",
      "surprise: 2701\n",
      "disgust: 1093\n",
      "happy: 5052\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Train--------\")\n",
    "# check the number of images in each class\n",
    "for cls in classes:\n",
    "    print(f'{cls}: {len(os.listdir(train_dir + cls))}')\n",
    "\n",
    "print(\"\\n--------Test--------\")\n",
    "# check the number of images in each class\n",
    "for cls in classes:\n",
    "    print(f'{cls}: {len(os.listdir(test_dir + cls))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d54f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Train--------\n",
      "\n",
      "--------Test--------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imghdr\n",
    "import shutil\n",
    "\n",
    "def delete_irrelevant_files(directory, classes):\n",
    "    for cls in classes:\n",
    "        class_dir = os.path.join(directory, cls)\n",
    "        with os.scandir(class_dir) as entries:\n",
    "            for entry in entries:\n",
    "                # Delete directories\n",
    "                if entry.is_dir():\n",
    "                    print(f'Deleting directory: {entry.path}')\n",
    "                    shutil.rmtree(entry.path)\n",
    "\n",
    "                # Check if the file is empty and delete it\n",
    "                elif os.path.getsize(entry.path) == 0:\n",
    "                    print(f'Deleting empty file: {entry.path}')\n",
    "                    os.remove(entry.path)\n",
    "\n",
    "                # Check if the file is not an image and delete it\n",
    "                elif not imghdr.what(entry.path):\n",
    "                    print(f'Deleting non-image file: {entry.path}')\n",
    "                    os.remove(entry.path)\n",
    "\n",
    "print(\"--------Train--------\")\n",
    "delete_irrelevant_files(train_dir, classes)\n",
    "\n",
    "print(\"\\n--------Test--------\")\n",
    "delete_irrelevant_files(test_dir, classes)\n",
    "\n",
    "#delete_irrelevant_files(b_train_dir, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184cd348",
   "metadata": {},
   "source": [
    "# Landmark detection from images and correlation of those landmark positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687d3d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image input size: 0.84 MB\n"
     ]
    }
   ],
   "source": [
    "image_size = torch.Size([48, 48, 3])\n",
    "batch_size = 32\n",
    "\n",
    "# Compute the total size of the image input\n",
    "image_input_size = np.prod(image_size) * batch_size * 4. / (1024 ** 2.)\n",
    "print(f\"Image input size: {image_input_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc48fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []  # new list to store the label index\n",
    "        for i, label in enumerate(os.listdir(root_dir)):\n",
    "            class_dir = os.path.join(root_dir, label)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                image = cv2.imread(img_path)\n",
    "                self.data.append(image)\n",
    "                self.labels.append(i)  # add the label index for this image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]  # get the label index for this image\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label  # return the image and label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fde4c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = LandmarkDataset(train_dir, transform=transform)\n",
    "val_dataset = LandmarkDataset(test_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e67fa6f-c829-4088-87a8-2a80c660a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=24)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b2c0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-voeu6urb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "0 torch.Size([256, 3, 64, 64]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# show shape of the train_dataloader\n",
    "for i, data in enumerate(train_dataloader):\n",
    "    print(i, data[0].shape, data[1].shape)\n",
    "    break\n",
    "\n",
    "# show shape of the val_dataloader\n",
    "for i, data in enumerate(val_dataloader):\n",
    "    print(i, data[0].shape, data[1].shape)\n",
    "    break\n",
    "\n",
    "# torch.Size([4, 3, 48, 48]) torch.Size([4])\n",
    "# torch.Size([4, 3, 48, 48]) torch.Size([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d283a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = input_dim // num_heads\n",
    "\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        qk = torch.matmul(query, key.transpose(-2, -1))\n",
    "        dk = query.size(-1)\n",
    "        scaled_attention_logits = qk / torch.sqrt(torch.tensor(dk, dtype=torch.float32, device=qk.device))\n",
    "\n",
    "        attention_weights = F.softmax(scaled_attention_logits, dim=-1)\n",
    "        output = torch.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        return x.transpose(1, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "\n",
    "        query = self.split_heads(query)\n",
    "        key = self.split_heads(key)\n",
    "        value = self.split_heads(value)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(query, key, value)\n",
    "        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.input_dim)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32162ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialExpressionDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_heads):\n",
    "        super(FacialExpressionDetectionModel, self).__init__()\n",
    "        \n",
    "        # Block-1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        # Block-2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        # Block-3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        # Block-4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.125)\n",
    "        )\n",
    "\n",
    "        # Block-5\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 128),  # Update the input size to match the new input shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        # Attention Layer\n",
    "        self.attention = MultiHeadAttention(128, num_heads)\n",
    "        self.attention_transform = nn.Linear(128, 64)\n",
    "\n",
    "\n",
    "        # Block-6\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64, 128),  # Update the input size to 64\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.125),\n",
    "        )\n",
    "\n",
    "        # Block-7\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.attention(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output of the attention layer\n",
    "        x = self.attention_transform(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0ba4b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aca52362",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "num_heads = 32\n",
    "model = FacialExpressionDetectionModel(num_classes, num_heads).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab8a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_v2.txt', 'w') as f:\n",
    "    f.write(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a07a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for data, targets in dataloader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Use autocast for mixed precision\n",
    "        with autocast():\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Scale the loss and perform backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        running_corrects += torch.sum(preds == targets.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31561c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in dataloader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "            # Use autocast for mixed precision\n",
    "            with autocast():\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "            running_corrects += torch.sum(preds == targets.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "488203d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = FacialExpressionDetectionModel(num_classes, num_heads).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, threshold=0.0001)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828ea399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57c79dfa-79fd-493e-8382-5ab4c8c7de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76d74a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Train Loss: 1.8313, Train Acc: 0.3198, Val Loss: 1.7982, Val Acc: 0.3517\n",
      "Epoch: 2/50, Train Loss: 1.7265, Train Acc: 0.4326, Val Loss: 1.7533, Val Acc: 0.3978\n",
      "Epoch: 3/50, Train Loss: 1.6774, Train Acc: 0.4832, Val Loss: 1.6921, Val Acc: 0.4633\n",
      "Epoch: 4/50, Train Loss: 1.6473, Train Acc: 0.5132, Val Loss: 1.6281, Val Acc: 0.5299\n",
      "Epoch: 5/50, Train Loss: 1.6216, Train Acc: 0.5395, Val Loss: 1.5925, Val Acc: 0.5677\n",
      "Epoch: 6/50, Train Loss: 1.6037, Train Acc: 0.5592, Val Loss: 1.5665, Val Acc: 0.5951\n",
      "Epoch: 7/50, Train Loss: 1.5874, Train Acc: 0.5759, Val Loss: 1.5562, Val Acc: 0.6062\n",
      "Epoch: 8/50, Train Loss: 1.5706, Train Acc: 0.5920, Val Loss: 1.5322, Val Acc: 0.6315\n",
      "Epoch: 9/50, Train Loss: 1.5573, Train Acc: 0.6064, Val Loss: 1.5327, Val Acc: 0.6312\n",
      "Epoch: 10/50, Train Loss: 1.5464, Train Acc: 0.6178, Val Loss: 1.5070, Val Acc: 0.6580\n",
      "Epoch: 11/50, Train Loss: 1.5358, Train Acc: 0.6278, Val Loss: 1.5077, Val Acc: 0.6577\n",
      "Epoch: 12/50, Train Loss: 1.5352, Train Acc: 0.6288, Val Loss: 1.5072, Val Acc: 0.6581\n",
      "Epoch: 13/50, Train Loss: 1.5380, Train Acc: 0.6255, Val Loss: 1.5085, Val Acc: 0.6563\n",
      "Epoch: 14/50, Train Loss: 1.5359, Train Acc: 0.6286, Val Loss: 1.5074, Val Acc: 0.6583\n",
      "Epoch: 15/50, Train Loss: 1.5362, Train Acc: 0.6283, Val Loss: 1.5063, Val Acc: 0.6589\n",
      "Epoch: 16/50, Train Loss: 1.5361, Train Acc: 0.6275, Val Loss: 1.5081, Val Acc: 0.6563\n",
      "Epoch: 17/50, Train Loss: 1.5356, Train Acc: 0.6295, Val Loss: 1.5070, Val Acc: 0.6583\n",
      "Epoch: 18/50, Train Loss: 1.5357, Train Acc: 0.6284, Val Loss: 1.5071, Val Acc: 0.6577\n",
      "Epoch: 19/50, Train Loss: 1.5347, Train Acc: 0.6298, Val Loss: 1.5071, Val Acc: 0.6581\n",
      "Epoch: 20/50, Train Loss: 1.5359, Train Acc: 0.6279, Val Loss: 1.5073, Val Acc: 0.6576\n",
      "Epoch: 21/50, Train Loss: 1.5359, Train Acc: 0.6278, Val Loss: 1.5075, Val Acc: 0.6577\n",
      "Epoch: 22/50, Train Loss: 1.5348, Train Acc: 0.6289, Val Loss: 1.5078, Val Acc: 0.6570\n",
      "Epoch: 23/50, Train Loss: 1.5359, Train Acc: 0.6273, Val Loss: 1.5073, Val Acc: 0.6585\n",
      "Epoch: 24/50, Train Loss: 1.5365, Train Acc: 0.6282, Val Loss: 1.5077, Val Acc: 0.6570\n",
      "Epoch: 25/50, Train Loss: 1.5368, Train Acc: 0.6264, Val Loss: 1.5078, Val Acc: 0.6572\n",
      "Epoch: 26/50, Train Loss: 1.5360, Train Acc: 0.6280, Val Loss: 1.5068, Val Acc: 0.6576\n",
      "Epoch: 27/50, Train Loss: 1.5361, Train Acc: 0.6282, Val Loss: 1.5069, Val Acc: 0.6577\n",
      "Epoch: 28/50, Train Loss: 1.5353, Train Acc: 0.6293, Val Loss: 1.5073, Val Acc: 0.6575\n",
      "Epoch: 29/50, Train Loss: 1.5342, Train Acc: 0.6297, Val Loss: 1.5075, Val Acc: 0.6573\n",
      "Epoch: 30/50, Train Loss: 1.5353, Train Acc: 0.6284, Val Loss: 1.5069, Val Acc: 0.6579\n",
      "Epoch: 31/50, Train Loss: 1.5340, Train Acc: 0.6295, Val Loss: 1.5074, Val Acc: 0.6574\n",
      "Epoch: 32/50, Train Loss: 1.5348, Train Acc: 0.6300, Val Loss: 1.5072, Val Acc: 0.6576\n",
      "Epoch: 33/50, Train Loss: 1.5364, Train Acc: 0.6273, Val Loss: 1.5077, Val Acc: 0.6571\n",
      "Epoch: 34/50, Train Loss: 1.5354, Train Acc: 0.6294, Val Loss: 1.5077, Val Acc: 0.6571\n",
      "Epoch: 35/50, Train Loss: 1.5359, Train Acc: 0.6279, Val Loss: 1.5071, Val Acc: 0.6573\n",
      "Epoch: 36/50, Train Loss: 1.5354, Train Acc: 0.6284, Val Loss: 1.5077, Val Acc: 0.6580\n",
      "Epoch: 37/50, Train Loss: 1.5357, Train Acc: 0.6283, Val Loss: 1.5082, Val Acc: 0.6567\n",
      "Epoch: 38/50, Train Loss: 1.5366, Train Acc: 0.6273, Val Loss: 1.5083, Val Acc: 0.6567\n",
      "Epoch: 39/50, Train Loss: 1.5348, Train Acc: 0.6298, Val Loss: 1.5072, Val Acc: 0.6573\n",
      "Epoch: 40/50, Train Loss: 1.5343, Train Acc: 0.6301, Val Loss: 1.5072, Val Acc: 0.6577\n",
      "Epoch: 41/50, Train Loss: 1.5341, Train Acc: 0.6297, Val Loss: 1.5077, Val Acc: 0.6569\n",
      "Epoch: 42/50, Train Loss: 1.5355, Train Acc: 0.6275, Val Loss: 1.5073, Val Acc: 0.6577\n",
      "Epoch: 43/50, Train Loss: 1.5344, Train Acc: 0.6303, Val Loss: 1.5087, Val Acc: 0.6557\n",
      "Epoch: 44/50, Train Loss: 1.5367, Train Acc: 0.6278, Val Loss: 1.5071, Val Acc: 0.6575\n",
      "Epoch: 45/50, Train Loss: 1.5361, Train Acc: 0.6279, Val Loss: 1.5069, Val Acc: 0.6578\n",
      "Epoch: 46/50, Train Loss: 1.5365, Train Acc: 0.6262, Val Loss: 1.5072, Val Acc: 0.6577\n",
      "Epoch: 47/50, Train Loss: 1.5357, Train Acc: 0.6286, Val Loss: 1.5068, Val Acc: 0.6583\n",
      "Epoch: 48/50, Train Loss: 1.5353, Train Acc: 0.6285, Val Loss: 1.5073, Val Acc: 0.6577\n",
      "Epoch: 49/50, Train Loss: 1.5369, Train Acc: 0.6271, Val Loss: 1.5075, Val Acc: 0.6574\n",
      "Epoch: 50/50, Train Loss: 1.5366, Train Acc: 0.6271, Val Loss: 1.5079, Val Acc: 0.6568\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create empty lists to store loss and accuracy for each epoch\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate_epoch(model, val_dataloader, criterion, device)\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # append the loss and accuracy to the lists\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d739b73-3926-4de7-94eb-ec7cd6d2bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Model saved as model_.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-874faf80d163>:17: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scaled_attention_logits = qk / torch.sqrt(torch.tensor(dk, dtype=torch.float32, device=qk.device))\n",
      "<ipython-input-11-874faf80d163>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scaled_attention_logits = qk / torch.sqrt(torch.tensor(dk, dtype=torch.float32, device=qk.device))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "dummy_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "\n",
    "onnx_filename = \"model_.onnx\"\n",
    "torch.onnx.export(model, dummy_input, onnx_filename)\n",
    "\n",
    "print(f\"Model saved as {onnx_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3ba05-e6dc-4393-877b-a795bc38c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = FacialExpressionDetectionModel(num_classes, num_heads).to(device)\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "scheduler2 = optim.lr_scheduler.StepLR(optimizer2, step_size=10, gamma=0.1)\n",
    "scaler2 = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432376b6-49df-4e14-9d0d-24796b5ddbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create empty lists to store loss and accuracy for each epoch\n",
    "train_loss_list2 = []\n",
    "train_acc_list2 = []\n",
    "val_loss_list2 = []\n",
    "val_acc_list2 = []\n",
    "\n",
    "num_epochs = 60\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model2, train_dataloader, criterion, optimizer2, device)\n",
    "    val_loss, val_acc = validate_epoch(model2, val_dataloader, criterion, device)\n",
    "    scheduler2.step(val_loss)\n",
    "    \n",
    "    # append the loss and accuracy to the lists\n",
    "    train_loss_list2.append(train_loss)\n",
    "    train_acc_list2.append(train_acc)\n",
    "    val_loss_list2.append(val_loss)\n",
    "    val_acc_list2.append(val_acc)\n",
    "\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c588ad5-92e0-4a33-9286-ea60e249e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = FacialExpressionDetectionModel(num_classes, num_heads).to(device)\n",
    "criterion3 = nn.CrossEntropyLoss()\n",
    "scaler3 = GradScaler()\n",
    "optimizer3 = optim.SGD(model3.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler3 = optim.lr_scheduler.CosineAnnealingLR(optimizer3, T_max=50, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483c960-2fab-47b2-91e4-39f10e19561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create empty lists to store loss and accuracy for each epoch\n",
    "train_loss_list3 = []\n",
    "train_acc_list3 = []\n",
    "val_loss_list3 = []\n",
    "val_acc_list3 = []\n",
    "\n",
    "num_epochs = 80\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model3, train_dataloader, criterion3, optimizer3, device)\n",
    "    val_loss, val_acc = validate_epoch(model3, val_dataloader, criterion3, device)\n",
    "    scheduler3.step(val_loss)\n",
    "    \n",
    "    # append the loss and accuracy to the lists\n",
    "    train_loss_list3.append(train_loss)\n",
    "    train_acc_list3.append(train_acc)\n",
    "    val_loss_list3.append(val_loss)\n",
    "    val_acc_list3.append(val_acc)\n",
    "\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ce6184e-fabc-4f4a-afd0-309d55b3f1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc_list = [float(t) for t in train_acc_list]\n",
    "val_acc_list = [float(t) for t in val_acc_list]\n",
    "\n",
    "train_acc_df = pd.DataFrame({'Epoch': range(len(train_acc_list)), 'Accuracy': train_acc_list, 'Type': 'Train'})\n",
    "val_acc_df = pd.DataFrame({'Epoch': range(len(val_acc_list)), 'Accuracy': val_acc_list, 'Type': 'Validation'})\n",
    "\n",
    "acc_df = pd.concat([train_acc_df, val_acc_df])\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=acc_df, x='Epoch', y='Accuracy', hue='Type')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Save the graph to a file\n",
    "plt.savefig('accuracy_graph.png', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db09c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to check pytorch version\n",
    "def check_pytorch_version():\n",
    "    if torch.__version__ >= '1.6.0':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# define a function to check cuda version\n",
    "def check_cuda_version():\n",
    "    if torch.cuda.is_available():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# define a function to check cudnn version\n",
    "def check_cudnn_version():\n",
    "    if check_cuda_version():\n",
    "        if torch.backends.cudnn.enabled:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# define a function to check if the system is ready for training\n",
    "def check_system():\n",
    "    if check_pytorch_version():\n",
    "        print('PyTorch version: {}'.format(torch.__version__))\n",
    "    else:\n",
    "        print('PyTorch version: {} (update required)'.format(torch.__version__))\n",
    "        \n",
    "    if check_cuda_version():\n",
    "        print('CUDA version: {}'.format(torch.version.cuda))\n",
    "    else:\n",
    "        print('CUDA version: {} (install CUDA to enable GPU training)'.format(torch.version.cuda))\n",
    "        \n",
    "    if check_cudnn_version():\n",
    "        print('cuDNN version: {}'.format(torch.backends.cudnn.version()))\n",
    "    else:\n",
    "        print('cuDNN version: {} (install cuDNN to enable GPU training)'.format(torch.backends.cudnn.version()))\n",
    "\n",
    "check_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0bf957-012e-41bb-838a-a2e7b9efeae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c838d3-272d-4749-a4bd-d2fbb9035436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cfe33-7a05-45cd-b35e-f21a874db635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
